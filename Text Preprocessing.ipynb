{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=\"\"\"Global warming is a phenomenon where the earth’s average temperature rises up due to increased amounts of greenhouse gases. Greenhouse gases such as carbon dioxide, methane and ozone trap the incoming radiation from the sun. This effect creates a natural “blanket” which prevents the heat from escaping back into the atmosphere. This effect is called a greenhouse effect.Contrary to popular belief, greenhouse gases are not inherently bad.  In fact, the greenhouse effect is quite important for life on earth. Without this effect, the sun’s radiation would be reflected back into the atmosphere, freezing the surface and making life impossible. However, when greenhouse gasses in excess amounts get trapped, serious repercussions begin to appear. The polar ice caps begin to melt, leading to the rise in sea levels. Furthermore, the greenhouse effect is accelerated when polar ice caps and sea ice melts. This is due to the fact the ice reflects 50% to 70% of the sun’s rays back into space; but without ice, the solar radiation gets absorbed. Seawater reflects only 6% of the sun’s radiation back into space. What’s more frightening is the fact that the poles contain large amounts of carbon dioxide trapped within the ice. If this ice melts, it will significantly contribute to global warming.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sentence tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1=nltk.sent_tokenize(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Global warming is a phenomenon where the earth’s average temperature rises up due to increased amounts of greenhouse gases.',\n",
       " 'Greenhouse gases such as carbon dioxide, methane and ozone trap the incoming radiation from the sun.',\n",
       " 'This effect creates a natural “blanket” which prevents the heat from escaping back into the atmosphere.',\n",
       " 'This effect is called a greenhouse effect.Contrary to popular belief, greenhouse gases are not inherently bad.',\n",
       " 'In fact, the greenhouse effect is quite important for life on earth.',\n",
       " 'Without this effect, the sun’s radiation would be reflected back into the atmosphere, freezing the surface and making life impossible.',\n",
       " 'However, when greenhouse gasses in excess amounts get trapped, serious repercussions begin to appear.',\n",
       " 'The polar ice caps begin to melt, leading to the rise in sea levels.',\n",
       " 'Furthermore, the greenhouse effect is accelerated when polar ice caps and sea ice melts.',\n",
       " 'This is due to the fact the ice reflects 50% to 70% of the sun’s rays back into space; but without ice, the solar radiation gets absorbed.',\n",
       " 'Seawater reflects only 6% of the sun’s radiation back into space.',\n",
       " 'What’s more frightening is the fact that the poles contain large amounts of carbon dioxide trapped within the ice.',\n",
       " 'If this ice melts, it will significantly contribute to global warming.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Global',\n",
       " 'warming',\n",
       " 'is',\n",
       " 'a',\n",
       " 'phenomenon',\n",
       " 'where',\n",
       " 'the',\n",
       " 'earth',\n",
       " '’',\n",
       " 's',\n",
       " 'average',\n",
       " 'temperature',\n",
       " 'rises',\n",
       " 'up',\n",
       " 'due',\n",
       " 'to',\n",
       " 'increased',\n",
       " 'amounts',\n",
       " 'of',\n",
       " 'greenhouse',\n",
       " 'gases',\n",
       " '.',\n",
       " 'Greenhouse',\n",
       " 'gases',\n",
       " 'such',\n",
       " 'as',\n",
       " 'carbon',\n",
       " 'dioxide',\n",
       " ',',\n",
       " 'methane',\n",
       " 'and',\n",
       " 'ozone',\n",
       " 'trap',\n",
       " 'the',\n",
       " 'incoming',\n",
       " 'radiation',\n",
       " 'from',\n",
       " 'the',\n",
       " 'sun',\n",
       " '.',\n",
       " 'This',\n",
       " 'effect',\n",
       " 'creates',\n",
       " 'a',\n",
       " 'natural',\n",
       " '“',\n",
       " 'blanket',\n",
       " '”',\n",
       " 'which',\n",
       " 'prevents',\n",
       " 'the',\n",
       " 'heat',\n",
       " 'from',\n",
       " 'escaping',\n",
       " 'back',\n",
       " 'into',\n",
       " 'the',\n",
       " 'atmosphere',\n",
       " '.',\n",
       " 'This',\n",
       " 'effect',\n",
       " 'is',\n",
       " 'called',\n",
       " 'a',\n",
       " 'greenhouse',\n",
       " 'effect.Contrary',\n",
       " 'to',\n",
       " 'popular',\n",
       " 'belief',\n",
       " ',',\n",
       " 'greenhouse',\n",
       " 'gases',\n",
       " 'are',\n",
       " 'not',\n",
       " 'inherently',\n",
       " 'bad',\n",
       " '.',\n",
       " 'In',\n",
       " 'fact',\n",
       " ',',\n",
       " 'the',\n",
       " 'greenhouse',\n",
       " 'effect',\n",
       " 'is',\n",
       " 'quite',\n",
       " 'important',\n",
       " 'for',\n",
       " 'life',\n",
       " 'on',\n",
       " 'earth',\n",
       " '.',\n",
       " 'Without',\n",
       " 'this',\n",
       " 'effect',\n",
       " ',',\n",
       " 'the',\n",
       " 'sun',\n",
       " '’',\n",
       " 's',\n",
       " 'radiation',\n",
       " 'would',\n",
       " 'be',\n",
       " 'reflected',\n",
       " 'back',\n",
       " 'into',\n",
       " 'the',\n",
       " 'atmosphere',\n",
       " ',',\n",
       " 'freezing',\n",
       " 'the',\n",
       " 'surface',\n",
       " 'and',\n",
       " 'making',\n",
       " 'life',\n",
       " 'impossible',\n",
       " '.',\n",
       " 'However',\n",
       " ',',\n",
       " 'when',\n",
       " 'greenhouse',\n",
       " 'gasses',\n",
       " 'in',\n",
       " 'excess',\n",
       " 'amounts',\n",
       " 'get',\n",
       " 'trapped',\n",
       " ',',\n",
       " 'serious',\n",
       " 'repercussions',\n",
       " 'begin',\n",
       " 'to',\n",
       " 'appear',\n",
       " '.',\n",
       " 'The',\n",
       " 'polar',\n",
       " 'ice',\n",
       " 'caps',\n",
       " 'begin',\n",
       " 'to',\n",
       " 'melt',\n",
       " ',',\n",
       " 'leading',\n",
       " 'to',\n",
       " 'the',\n",
       " 'rise',\n",
       " 'in',\n",
       " 'sea',\n",
       " 'levels',\n",
       " '.',\n",
       " 'Furthermore',\n",
       " ',',\n",
       " 'the',\n",
       " 'greenhouse',\n",
       " 'effect',\n",
       " 'is',\n",
       " 'accelerated',\n",
       " 'when',\n",
       " 'polar',\n",
       " 'ice',\n",
       " 'caps',\n",
       " 'and',\n",
       " 'sea',\n",
       " 'ice',\n",
       " 'melts',\n",
       " '.',\n",
       " 'This',\n",
       " 'is',\n",
       " 'due',\n",
       " 'to',\n",
       " 'the',\n",
       " 'fact',\n",
       " 'the',\n",
       " 'ice',\n",
       " 'reflects',\n",
       " '50',\n",
       " '%',\n",
       " 'to',\n",
       " '70',\n",
       " '%',\n",
       " 'of',\n",
       " 'the',\n",
       " 'sun',\n",
       " '’',\n",
       " 's',\n",
       " 'rays',\n",
       " 'back',\n",
       " 'into',\n",
       " 'space',\n",
       " ';',\n",
       " 'but',\n",
       " 'without',\n",
       " 'ice',\n",
       " ',',\n",
       " 'the',\n",
       " 'solar',\n",
       " 'radiation',\n",
       " 'gets',\n",
       " 'absorbed',\n",
       " '.',\n",
       " 'Seawater',\n",
       " 'reflects',\n",
       " 'only',\n",
       " '6',\n",
       " '%',\n",
       " 'of',\n",
       " 'the',\n",
       " 'sun',\n",
       " '’',\n",
       " 's',\n",
       " 'radiation',\n",
       " 'back',\n",
       " 'into',\n",
       " 'space',\n",
       " '.',\n",
       " 'What',\n",
       " '’',\n",
       " 's',\n",
       " 'more',\n",
       " 'frightening',\n",
       " 'is',\n",
       " 'the',\n",
       " 'fact',\n",
       " 'that',\n",
       " 'the',\n",
       " 'poles',\n",
       " 'contain',\n",
       " 'large',\n",
       " 'amounts',\n",
       " 'of',\n",
       " 'carbon',\n",
       " 'dioxide',\n",
       " 'trapped',\n",
       " 'within',\n",
       " 'the',\n",
       " 'ice',\n",
       " '.',\n",
       " 'If',\n",
       " 'this',\n",
       " 'ice',\n",
       " 'melts',\n",
       " ',',\n",
       " 'it',\n",
       " 'will',\n",
       " 'significantly',\n",
       " 'contribute',\n",
       " 'to',\n",
       " 'global',\n",
       " 'warming',\n",
       " '.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word=nltk.word_tokenize(p)\n",
    "word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "249"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using regular expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Global warming is a phenomenon where the earth’s average temperature rises up due to increased amounts of greenhouse gases',\n",
       " ' Greenhouse gases such as carbon dioxide, methane and ozone trap the incoming radiation from the sun',\n",
       " ' This effect creates a natural “blanket” which prevents the heat from escaping back into the atmosphere',\n",
       " ' This effect is called a greenhouse effect',\n",
       " 'Contrary to popular belief, greenhouse gases are not inherently bad',\n",
       " '  In fact, the greenhouse effect is quite important for life on earth',\n",
       " ' Without this effect, the sun’s radiation would be reflected back into the atmosphere, freezing the surface and making life impossible',\n",
       " ' However, when greenhouse gasses in excess amounts get trapped, serious repercussions begin to appear',\n",
       " ' The polar ice caps begin to melt, leading to the rise in sea levels',\n",
       " ' Furthermore, the greenhouse effect is accelerated when polar ice caps and sea ice melts',\n",
       " ' This is due to the fact the ice reflects 50% to 70% of the sun’s rays back into space; but without ice, the solar radiation gets absorbed',\n",
       " ' Seawater reflects only 6% of the sun’s radiation back into space',\n",
       " ' What’s more frightening is the fact that the poles contain large amounts of carbon dioxide trapped within the ice',\n",
       " ' If this ice melts, it will significantly contribute to global warming',\n",
       " '']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s=r\"[?.]\"\n",
    "re.split(s,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Global',\n",
       " 'Greenhouse',\n",
       " 'This',\n",
       " 'This',\n",
       " 'Contrary',\n",
       " 'In',\n",
       " 'Without',\n",
       " 'However',\n",
       " 'The',\n",
       " 'Furthermore',\n",
       " 'This',\n",
       " 'Seawater',\n",
       " 'What',\n",
       " 'If']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern=r\"[A-Z]\\w+\"\n",
    "re.findall(pattern,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi! How are you? Have a Great Day.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r=\"Hello! How are you? Have a Great Day.\"\n",
    "re.sub(\"Hello\",\"Hi\",r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'play'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem(\"playing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'work'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem(\"working\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'freez'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem(\"freezing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['global warm is a phenomenon where the earth ’ s averag temperatur rise up due to increas amount of greenhous gase .',\n",
       " 'greenhous gase such as carbon dioxid , methan and ozon trap the incom radiat from the sun .',\n",
       " 'thi effect creat a natur “ blanket ” which prevent the heat from escap back into the atmospher .',\n",
       " 'thi effect is call a greenhous effect.contrari to popular belief , greenhous gase are not inher bad .',\n",
       " 'In fact , the greenhous effect is quit import for life on earth .',\n",
       " 'without thi effect , the sun ’ s radiat would be reflect back into the atmospher , freez the surfac and make life imposs .',\n",
       " 'howev , when greenhous gass in excess amount get trap , seriou repercuss begin to appear .',\n",
       " 'the polar ice cap begin to melt , lead to the rise in sea level .',\n",
       " 'furthermor , the greenhous effect is acceler when polar ice cap and sea ice melt .',\n",
       " 'thi is due to the fact the ice reflect 50 % to 70 % of the sun ’ s ray back into space ; but without ice , the solar radiat get absorb .',\n",
       " 'seawat reflect onli 6 % of the sun ’ s radiat back into space .',\n",
       " 'what ’ s more frighten is the fact that the pole contain larg amount of carbon dioxid trap within the ice .',\n",
       " 'If thi ice melt , it will significantli contribut to global warm .']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(sentence1)):\n",
    "    words=nltk.word_tokenize(sentence1[i])\n",
    "    words=[stemmer.stem(word) for word in words]\n",
    "    sentence1[i]=\" \".join(words)\n",
    "sentence1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "!\n",
      "What\n",
      "?\n",
      "Nice\n",
      "meet\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "Sent1=\"Hello! What are you doing? Nice to meet you.\"\n",
    "words=nltk.word_tokenize(Sent1)\n",
    "for i in words:\n",
    "    if i not in stopwords.words(\"english\"):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part of Speech tag  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Hello', 'NN'),\n",
       " ('!', '.'),\n",
       " ('What', 'WP'),\n",
       " ('are', 'VBP'),\n",
       " ('you', 'PRP'),\n",
       " ('doing', 'VBG'),\n",
       " ('?', '.'),\n",
       " ('Nice', 'NNP'),\n",
       " ('to', 'TO'),\n",
       " ('meet', 'VB'),\n",
       " ('you', 'PRP'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tag(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemm=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemm.lemmatize(\"running\",pos=\"v\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence=\"This is an example\"\n",
    "words=nltk.word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('This', 'is', 'an')\n",
      "('is', 'an', 'example')\n"
     ]
    }
   ],
   "source": [
    "for i in ngrams(words,3):    # tri grams example   n=3 \n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Vectors from Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words\n",
    "<br>\n",
    "creates a set of vectors containing the count of word occurrences in the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1=\"Hello, This is line one one. This is second line. This is example of Bag of words.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1=nltk.sent_tokenize(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello line one one', 'second line', 'example bag words']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=[]\n",
    "for i in range(len(sentence1)):\n",
    "    new=re.sub('[^a-zA-Z]',\" \",sentence1[i])\n",
    "    new=new.lower()\n",
    "    new=new.split()\n",
    "    new=[i for i in new if i not in set(stopwords.words('english'))]\n",
    "    new=\" \".join(new)\n",
    "    data.append(new)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv=CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "r=cv.fit_transform(data).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "r=pd.DataFrame(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4  5  6\n",
       "0  0  0  1  1  2  0  0\n",
       "1  0  0  0  1  0  1  0\n",
       "2  1  1  0  0  0  0  1"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drawback of BoW is that it convert to data where all features have equal importance and TF-IDF is used to overcome this problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF  Term Frequency-Inverse Document Frequency\n",
    "\n",
    "tf=no. of particular word in sentence / Total number of words in sentence <br>\n",
    "idf=no. of sentences / no. of sentences containing particular word <br>\n",
    "resultant tfidf = tf * idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf=TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "z=tfidf.fit_transform(data).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.423394</td>\n",
       "      <td>0.322002</td>\n",
       "      <td>0.846789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.605349</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.795961</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.57735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0        1         2         3         4         5        6\n",
       "0  0.00000  0.00000  0.423394  0.322002  0.846789  0.000000  0.00000\n",
       "1  0.00000  0.00000  0.000000  0.605349  0.000000  0.795961  0.00000\n",
       "2  0.57735  0.57735  0.000000  0.000000  0.000000  0.000000  0.57735"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z=pd.DataFrame(z)\n",
    "z"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
